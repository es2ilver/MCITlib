{
  "gpu_num": 4,
  "rank": 32,
  "previous_model": "/mnt/ShareDB_6TB/datasets/MLLM_CL/checkpoints/MLLM-DCL/LLaVA-1.5/LoRA/Task1_llava_lora",
  "output_dir": "/mnt/ShareDB_6TB/datasets/MLLM_CL/checkpoints/MLLM-DCL/LLaVA-1.5/LoRA/Task2_llava_lora",
  "epoch": 3,
  "batch_size": 4,
  "grad_acc": 2,
  "lr": 2e-5
}
